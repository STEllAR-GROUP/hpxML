<!-- Copyright (c) 2014 John Biddiscombe                                          -->
<!--                                                                              -->
<!-- Distributed under the Boost Software License, Version 1.0. (See accompanying -->
<!-- file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)        -->

Not Finished yet.


The network storage benchmark comes with several files

##################################################
# What the files are for
##################################################

------------------------------
network_storage.cpp 
------------------------------
This is the code for the test.

------------------------------
network_storage.bat.in 
------------------------------
This is a windows batch file template which will be filled in using cmake substitution
and then copied to your build/scripts directory.
The generated script can be invoked to run the benchmark in serial or parallel. 
It spawns each task on the same node so although you may run 4 copies, 
they are competing for resources. 
The windows version is good for testing and debugging on a single node.
adding or removing /B for the launch command in the script
controls whether each task is launched in a new console window or not
example usage (2 tasks)
scripts/network_storage.bat 2

------------------------------
slurm-test-HPX-storage.sh.in
------------------------------
This is a bash script template which will be filled in using cmake substitution
and then copied to your build/scripts directory.
When executed, the script will loop over a number of parameter combinations
and for each create a directory with a name generated from the paramaters, such as
  hpx-N0002-T02048-t04-ibverbs
and inside the dir there will be a "submit-job.bash" script which contains a single
slurm job submission. You can manually submit just one job using "sbatch submit-job.bash", 
or in the root of the scripts folder there will be generated another script 
which is called "run_jobs.bash". When this script is run, it will loop over
the jobs that were created by the first script and submit them all, you
can then sit back and wait until they complete.
Each job will write its results into "slurm.out" (and errors to slurm.err)
in the same subdirectory in which each individual job submission script was created.

The network_storage executable will produce several lines of output, but one line
contains the condensed information needed by the plotting script. 
This line begins with the text "CSVData" to indicate comma separated data values.
Whilst jobs are running or when they have completed, you can execute a command
such as
  find . -name slurm.out -exec grep CSV {} \;
and a list of results generated from the jobs will be produced.
For plotting of results, the output should be directed into a file using
  find . -name slurm.out -exec grep CSV {} \; >results-bgq-1a-2014-04-01.csv
Where you use a file name useful to your current experiment.
The generated file will be suitable for use by the plotting script.

------------------------------
plot-results.py
------------------------------
This is a python script which takes results generated by the test program
and plots a number of graphs for different parameter studies.
The results.csv file generated contains BW measurements, timing ,thread, parcelport,
block size, etc information for the plots. 
The python script parses the results and generates arrays (maps) of the data which
can be plotted in various ways. The scripts can be invoked as
  plot-results.py results.csv
optional arguments such as the figure size can be found by looking at the script.
The outpur from the script will be a series of svg and png files for each of the plots
created.


